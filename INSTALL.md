# H∆∞·ªõng d·∫´n C√†i ƒë·∫∑t PaddleOCR API

T√†i li·ªáu h∆∞·ªõng d·∫´n c√†i ƒë·∫∑t v√† tri·ªÉn khai API OCR s·ª≠ d·ª•ng FastAPI v√† PaddleOCR.

---

## üìã Y√™u c·∫ßu H·ªá th·ªëng

### Ph·∫ßn c·ª©ng
- **RAM**: T·ªëi thi·ªÉu 8GB (khuy·∫øn ngh·ªã 16GB+)
- **GPU**: NVIDIA GPU v·ªõi CUDA support (khuy·∫øn ngh·ªã)
  - VRAM: T·ªëi thi·ªÉu 4GB
  - CUDA: 11.2+ ho·∫∑c 12.x
- **·ªî c·ª©ng**: 10GB tr·ªëng (cho models v√† dependencies)

### Ph·∫ßn m·ªÅm
- **OS**: Linux (Ubuntu 20.04+), Windows 10/11, ho·∫∑c WSL2
- **Python**: 3.8, 3.9, ho·∫∑c 3.10
- **CUDA Toolkit**: 11.2+ (n·∫øu d√πng GPU)
- **cuDNN**: 8.x (n·∫øu d√πng GPU)

---

## üöÄ C√†i ƒë·∫∑t

### B∆∞·ªõc 1: Chu·∫©n b·ªã M√¥i tr∆∞·ªùng

#### T·∫°o virtual environment (khuy·∫øn ngh·ªã)

```bash
# S·ª≠ d·ª•ng conda (khuy·∫øn ngh·ªã)
conda create -n ppocr python=3.9
conda activate ppocr

# Ho·∫∑c s·ª≠ d·ª•ng venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ho·∫∑c
venv\Scripts\activate  # Windows
```

### B∆∞·ªõc 2: C√†i ƒë·∫∑t PaddlePaddle

#### V·ªõi GPU (CUDA 11.2+)

```bash
python -m pip install paddlepaddle-gpu==3.2 -i https://pypi.tuna.tsinghua.edu.cn/simple
```

#### Ch·ªâ CPU

```bash
python -m pip install paddlepaddle==3.2 -i https://pypi.tuna.tsinghua.edu.cn/simple
```

#### C·∫•u h√¨nh LD_LIBRARY_PATH (Linux/WSL - QUAN TR·ªåNG!)

N·∫øu d√πng GPU, c·∫ßn set `LD_LIBRARY_PATH` ƒë·ªÉ PaddlePaddle t√¨m ƒë∆∞·ª£c CUDA libraries:

```bash
# Ki·ªÉm tra CUDA installation path
which nvcc
# Output th∆∞·ªùng l√†: /usr/local/cuda-11.x/bin/nvcc ho·∫∑c /usr/local/cuda/bin/nvcc

# Set LD_LIBRARY_PATH (thay ƒë·ªïi version CUDA cho ph√π h·ª£p)
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
export LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH

# ƒê·ªÉ permanent, th√™m v√†o ~/.bashrc ho·∫∑c ~/.zshrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

**V·ªõi Conda environment:**
```bash
# Set cho specific conda env
conda activate ppocr
conda env config vars set LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH

# Ho·∫∑c t·∫°o activation script
mkdir -p $CONDA_PREFIX/etc/conda/activate.d
echo 'export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH' > $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh
```

#### Ki·ªÉm tra c√†i ƒë·∫∑t

```python
import paddle
print(paddle.__version__)
print("GPU available:", paddle.is_compiled_with_cuda())

# Ki·ªÉm tra CUDA device
import paddle
paddle.device.set_device('gpu:0')
print("CUDA device:", paddle.device.get_device())
```

### B∆∞·ªõc 3: C√†i ƒë·∫∑t Dependencies

```bash
cd d:/ThucTap/OCR_Labs/padd_OCR

# C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
pip install -r requirements.txt
```

**N·ªôi dung `requirements.txt`:**
```
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
python-multipart>=0.0.6
paddleocr>=2.7.0
Pillow>=10.0.0
aiofiles>=23.2.1
pydantic>=2.0.0
```

### B∆∞·ªõc 4: C√†i ƒë·∫∑t PaddleOCR

```bash
pip install paddleocr>=2.7.0
```

### B∆∞·ªõc 5: C·∫•u h√¨nh Custom Model

#### Download ho·∫∑c copy custom model

ƒê·∫£m b·∫£o custom text recognition model ƒë√£ c√≥ t·∫°i:
```
/mnt/d/ThucTap/OCR_Labs/models/tdd_ocr/
```

Ho·∫∑c update ƒë∆∞·ªùng d·∫´n trong `config.py`:

```python
TEXT_OCR_CONFIG = {
    "text_recognition_model_dir": "/path/to/your/custom/model",
    # ...
}
```

---

## ‚öôÔ∏è C·∫•u h√¨nh

### File `config.py`

Ch·ªânh s·ª≠a c√°c th√¥ng s·ªë trong `config.py`:

#### 1. GPU/CPU Mode

```python
USE_GPU = True  # Set False n·∫øu ch·ªâ d√πng CPU
```

#### 2. Model Paths

```python
TEXT_OCR_CONFIG = {
    "text_recognition_model_dir": "/mnt/d/ThucTap/OCR_Labs/models/tdd_ocr",
    # Adjust path theo h·ªá th·ªëng c·ªßa b·∫°n
}

TABLE_OCR_CONFIG = {
    "text_recognition_model_dir": "/mnt/d/ThucTap/OCR_Labs/models/tdd_ocr",
    # Adjust path theo h·ªá th·ªëng c·ªßa b·∫°n
}
```

#### 3. File Upload Settings

```python
MAX_UPLOAD_SIZE = 10 * 1024 * 1024  # 10MB (adjust n·∫øu c·∫ßn)
ALLOWED_EXTENSIONS = {".jpg", ".jpeg", ".png", ".bmp", ".tiff", ".webp"}
```

#### 4. CORS Origins (n·∫øu c√≥ frontend)

```python
CORS_ORIGINS = [
    "http://localhost:3000",
    "http://your-frontend-domain.com",
]
```

---

## üèÉ Ch·∫°y Server

### Development Mode (v·ªõi auto-reload)

```bash
# T·ª´ th∆∞ m·ª•c padd_OCR
python main.py

# Ho·∫∑c s·ª≠ d·ª•ng uvicorn
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Production Mode

```bash
# S·ª≠ d·ª•ng gunicorn v·ªõi uvicorn workers
pip install gunicorn

gunicorn main:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000 \
  --timeout 120 \
  --access-logfile - \
  --error-logfile -
```

### Background Mode (Linux)

```bash
# S·ª≠ d·ª•ng nohup
nohup python main.py > server.log 2>&1 &

# Ho·∫∑c systemd service (xem ph·∫ßn Deploy)
```

---

## üß™ Ki·ªÉm tra C√†i ƒë·∫∑t

### 1. Health Check

```bash
curl http://localhost:8000/health
```

**Expected output:**
```json
{
  "status": "healthy",
  "service": "paddleocr_api",
  "gpu_enabled": true
}
```

### 2. Test Text OCR

```bash
curl -X POST "http://localhost:8000/ocr" \
  -F "file=@test_image.png"
```

### 3. Test Table OCR

```bash
curl -X POST "http://localhost:8000/table?format=markdown" \
  -F "file=@table_image.png"
```

### 4. API Documentation

Truy c·∫≠p trong browser:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

---

## üê≥ Docker Deployment (Optional)

### Dockerfile

```dockerfile
FROM python:3.9-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    libgomp1 \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copy requirements and install
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

# Expose port
EXPOSE 8000

# Run server
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Build & Run

```bash
# Build image
docker build -t paddleocr-api .

# Run container (CPU)
docker run -p 8000:8000 paddleocr-api

# Run container (GPU) - requires nvidia-docker
docker run --gpus all -p 8000:8000 paddleocr-api
```

---

## üîß Troubleshooting

### L·ªói: ModuleNotFoundError: No module named 'fastapi'

```bash
pip install fastapi uvicorn python-multipart
```

### L·ªói: CUDA not available

**Ki·ªÉm tra:**
```python
import paddle
print(paddle.is_compiled_with_cuda())
```

**Gi·∫£i ph√°p:**
1. Ki·ªÉm tra CUDA installation:
   ```bash
   nvcc --version
   nvidia-smi
   ```

2. **Ki·ªÉm tra LD_LIBRARY_PATH** (Linux/WSL):
   ```bash
   echo $LD_LIBRARY_PATH
   # Ph·∫£i include /usr/local/cuda/lib64
   
   # N·∫øu ch∆∞a c√≥, set l·∫°i:
   export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
   ```

3. C√†i ƒë·∫∑t l·∫°i paddlepaddle-gpu v·ªõi ƒë√∫ng CUDA version

4. Ho·∫∑c set `USE_GPU = False` trong config.py n·∫øu kh√¥ng c·∫ßn GPU

### L·ªói: libcudnn.so.x not found

```bash
# L·ªói: libcudnn.so.8: cannot open shared object file
```

**Gi·∫£i ph√°p:**
```bash
# Ki·ªÉm tra cuDNN ƒë√£ c√†i ch∆∞a
ldconfig -p | grep cudnn

# N·∫øu ch∆∞a, c√†i cuDNN ho·∫∑c add v√†o LD_LIBRARY_PATH
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH

# Verify
python -c "import paddle; print(paddle.device.cuda.device_count())"
```

### L·ªói: Model not found

**Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n:**
```bash
ls -la /mnt/d/ThucTap/OCR_Labs/models/tdd_ocr/
```

**C·∫≠p nh·∫≠t config.py** v·ªõi ƒë∆∞·ªùng d·∫´n ƒë√∫ng.

### L·ªói: Address already in use (port 8000)

```bash
# T√¨m process ƒëang d√πng port 8000
# Linux/Mac
lsof -i :8000
# Windows
netstat -ano | findstr :8000

# Kill process ho·∫∑c ƒë·ªïi port
uvicorn main:app --port 8001
```

### Server ch·∫≠m khi request ƒë·∫ßu ti√™n

**B√¨nh th∆∞·ªùng!** Models ƒëang ƒë∆∞·ª£c load l·∫ßn ƒë·∫ßu (3-5 gi√¢y). C√°c request sau s·∫Ω nhanh h∆°n nhi·ªÅu do model caching.

### Out of Memory Error

**Gi·∫£i ph√°p:**
1. Gi·∫£m batch size (n·∫øu c√≥)
2. Gi·∫£m MAX_UPLOAD_SIZE
3. Set `USE_GPU = False` n·∫øu VRAM kh√¥ng ƒë·ªß
4. TƒÉng RAM/VRAM

---

## üìä Monitoring & Logs

### Xem logs

```bash
# Development mode
# Logs hi·ªÉn th·ªã tr·ª±c ti·∫øp tr√™n terminal

# Production v·ªõi gunicorn
tail -f /var/log/paddleocr-api/access.log
tail -f /var/log/paddleocr-api/error.log
```

### Performance Monitoring

```python
# Th√™m logging v√†o code
import logging
logging.basicConfig(level=logging.INFO)
```

---

## üîê Security (Production)

### 1. API Key Authentication (Optional)

Th√™m middleware authentication trong `main.py`.

### 2. Rate Limiting

```bash
pip install slowapi

# Add to main.py
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
```

### 3. HTTPS

S·ª≠ d·ª•ng reverse proxy (nginx) v·ªõi SSL certificate.

---

## üéØ Next Steps

1. ‚úÖ Test API v·ªõi c√°c lo·∫°i ·∫£nh kh√°c nhau
2. ‚úÖ Monitor performance v√† memory usage
3. ‚úÖ Set up monitoring (Prometheus/Grafana)
4. ‚úÖ Configure backup cho models
5. ‚úÖ Set up CI/CD pipeline

---

## üìû Support

- **Issues**: T·∫°o issue tr√™n repository
- **Documentation**: Xem `API_README.md` cho API usage
- **PaddleOCR Docs**: https://github.com/PaddlePaddle/PaddleOCR

---

## üìù Changelog

- **v1.0.0** (2025-11-28)
  - Initial release
  - Text OCR endpoint
  - Table OCR endpoint
  - Model caching
  - Async processing
